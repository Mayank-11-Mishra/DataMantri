# ğŸš€ Simple Start (SQLite - No External Dependencies)

Ultra-simple setup using SQLite and in-memory task queue. **No PostgreSQL or Redis required!**

---

## âš¡ Quick Start

### **Step 1: Setup Environment**

```bash
cd "/Users/sunny.agarwal/Projects/DataMantri - Cursor/pipeline_orchestrator"

# Copy SQLite configuration
cp backend/.env.sqlite backend/.env
```

### **Step 2: Initialize Database**

```bash
cd backend
python init_db.py
```

### **Step 3: Start Services** (3 separate terminals)

**Terminal 1: Backend API**
```bash
cd "/Users/sunny.agarwal/Projects/DataMantri - Cursor/pipeline_orchestrator/backend"
python -m uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2: Celery Worker**
```bash
cd "/Users/sunny.agarwal/Projects/DataMantri - Cursor/pipeline_orchestrator/backend"
python -m celery -A app.tasks.celery_app worker --loglevel=info --pool=solo
```

**Terminal 3: Frontend**
```bash
cd "/Users/sunny.agarwal/Projects/DataMantri - Cursor/pipeline_orchestrator/frontend"
npm run dev
```

---

## ğŸŒ Access

- **Frontend:** http://localhost:3000
- **API Docs:** http://localhost:8000/api/v1/docs

**Login:**
- Email: `admin@datamantri.com`
- Password: `admin123`

---

## âš ï¸ Limitations of Simple Setup

This setup uses:
- **SQLite** instead of PostgreSQL (good for development, not for production)
- **In-memory broker** instead of Redis (tasks won't persist across restarts)
- **No Celery Beat** (scheduled tasks won't work automatically)

**Good for:**
- âœ… Development & testing
- âœ… Learning the system
- âœ… Demo purposes
- âœ… Manual pipeline execution

**Not good for:**
- âŒ Production use
- âŒ Automatic scheduled execution
- âŒ High concurrency
- âŒ Distributed systems

---

## ğŸ”„ Upgrade to Full Setup Later

When ready, switch to PostgreSQL + Redis:

1. Install Homebrew:
   ```bash
   /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
   ```

2. Install services:
   ```bash
   brew install postgresql@14 redis
   brew services start postgresql@14 redis
   ```

3. Update `.env` file with PostgreSQL connection

---

## ğŸ“ Database Files

SQLite will create these files in the `backend/` directory:
- `datamantri_pipelines.db` - Main database
- `celery_results.db` - Task results

To reset:
```bash
cd backend
rm *.db
python init_db.py
```

---

## âœ… Advantages

- âœ… No external dependencies
- âœ… Works out of the box
- âœ… Perfect for development
- âœ… Easy to reset
- âœ… Fast setup

---

## ğŸ¯ You're Ready!

The simple setup is perfect for getting started. You can still:
- Create pipelines
- Execute them manually
- View execution history
- Test BigQuery â†’ PostgreSQL transfers
- Use the full UI

**Start now:** Just run the 3 terminal commands above!


